{"posts":[{"title":"Time Series Basics","content":"[toc] Definition Stochastic process: A stochastic process is a collection of random variables {Xt}t∈T\\lbrace X_t\\rbrace_{t \\in T}{Xt​}t∈T​ indexed by a set TTT , i.e. t∈Tt \\in Tt∈T defined on a probability space (Ω,F,P)( \\Omega, \\mathcal {F},P)(Ω,F,P). (Not necessarily independent) If TTT consists of the integers (or a subset), the process is called a Discrete Time Stochastic Process. If TTT consists of the real numbers (or a subset), the process is called Continuous Time Stochastic Process. Realization: A realization of {Xt}\\lbrace X_t\\rbrace{Xt​} is the outcome {xt}t∈T\\lbrace x_t\\rbrace_{t \\in T}{xt​}t∈T​ = {Xt(ω)}t∈T\\lbrace X_t(\\omega)\\rbrace_{t \\in T}{Xt​(ω)}t∈T​ for some ω∈Ω\\omega \\in \\Omegaω∈Ω. Time Series: 'We use the term time series whether we are referring generically to the process or to a particular realization and make no notational distinction between the two concepts.'[1] Describing a stochastic process A simpler, more useful way of describing a stochastic process is to give the moments of the process, particularly the ﬁrst and second moments that are called the mean and autocovariance function (acv.f.), respectively.[2] Mean The mean function μ(t)\\mu(t)μ(t) is deﬁned for all ttt by μ(t)=E[X(t)]\\mu(t) = E[X(t)] μ(t)=E[X(t)] Autocovariance The variance function σ2(t)\\sigma^2(t)σ2(t) is deﬁned for all ttt by σ2(t)=Var[X(t)]=E[(X(t)−μ(t))2]\\sigma^2(t)=Var[X(t)]=E[(X(t)-\\mu(t))^2] σ2(t)=Var[X(t)]=E[(X(t)−μ(t))2] The variance function alone is not enough to specify the second moments of a sequence of random variables. More generally, we deﬁne the acv.f. γ(t1,t2)\\gamma(t_1,t_2)γ(t1​,t2​) to be the covariance of X(t1)X(t_1)X(t1​) with X(t2)X(t_2)X(t2​), namely γ(t1,t2)=E{[X(t1)−μ(t1)][X(t2)−μ(t2)]}\\gamma(t_1,t_2)=E\\lbrace [X(t_1)-\\mu(t_1)][X(t_2)-\\mu(t_2)]\\rbrace γ(t1​,t2​)=E{[X(t1​)−μ(t1​)][X(t2​)−μ(t2​)]} The variance function is a special case of the acv.f. when t1=t2t_1 = t_2t1​=t2​. The autocorrelation function is defined as ρ(t1,t2)=γ(t1,t2){γ(t1,t1)γ(t2,t2)}1/2\\rho(t_1,t_2)=\\frac{\\gamma(t_1,t_2)}{\\lbrace \\gamma(t_1,t_1)\\gamma(t_2,t_2)\\rbrace ^{1/2}} ρ(t1​,t2​)={γ(t1​,t1​)γ(t2​,t2​)}1/2γ(t1​,t2​)​ Some classes of stochastic processes Stationary Processes An important class of stochastic processes are those that are stationary. Intuitive Point of View Broadly speaking a time series is said to be stationary if there is no systematic change in mean (no trend), if there is no systematic change in variance and if strictly periodic variations have been removed. In other words, the properties of one section of the data are much like those of any other section.[2:1] Mathematical Deﬁnition A time series is said to be strictly stationary if the joint distribution of X(t1),...,X(tk)X(t_1), . . . , X(t_k)X(t1​),...,X(tk​) is the same as the joint distribution of X(t1+τ),...,X(tk+τ)X(t_{1+\\tau}), . . . , X(t_{k+\\tau})X(t1+τ​),...,X(tk+τ​) for all t1,...,tk,τt_1, . . . , t_k, \\taut1​,...,tk​,τ. second-order stationary (or weakly stationary) if the mean is constant and the covariance function γ(s,t)\\gamma(s, t)γ(s,t) depends only on the lag ∣t−s∣(τ)|t − s|(\\tau)∣t−s∣(τ). Thus, the autocovariance function can be written as γ(t,t+τ)=γ(0,τ)=γ(0,−τ)≡γ∣τ∣=γτ\\gamma(t,t+\\tau)=\\gamma(0,\\tau)=\\gamma(0,-\\tau)\\equiv \\gamma_{|\\tau|}=\\gamma_\\tau γ(t,t+τ)=γ(0,τ)=γ(0,−τ)≡γ∣τ∣​=γτ​ τ∈Z\\tau \\in \\mathcal {Z}τ∈Z. The autocorrelation function can be written as ρ(t,t+τ)≡ρ∣τ∣=ρτ\\rho(t,t+\\tau)\\equiv \\rho_{|\\tau|}=\\rho_\\tau ρ(t,t+τ)≡ρ∣τ∣​=ρτ​ In the stationary case the covariance and correlation functions are symmetric around τ=0\\tau = 0τ=0. Purely Random Processes (White Noise) A stochastic process Xt{X_t}Xt​ is called white noise if its elements are uncorrelated, mean E(Xt)=0E(X_t) = 0E(Xt​)=0 and variance Var(Xt)=σ2Var(X_t) = \\sigma^2Var(Xt​)=σ2. γ(k)=Cov(Xt,Xt+k)={σX2,k=00,k=±1,±2,...\\gamma(k)=Cov(X_t,X_{t+k})=\\begin{cases}\\sigma^2_X, &amp;k=0 \\cr 0, &amp;k=\\pm1,\\pm2,... \\end{cases} γ(k)=Cov(Xt​,Xt+k​)={σX2​,0,​k=0k=±1,±2,...​ ρ(k)=Cor(Xt,Xt+k)={1,k=00,k=±1,±2,...\\rho(k)=Cor(X_t,X_{t+k})=\\begin{cases}1, &amp;k=0 \\cr 0, &amp;k=\\pm1,\\pm2,... \\end{cases} ρ(k)=Cor(Xt​,Xt+k​)={1,0,​k=0k=±1,±2,...​ If in addition the XtX_tXt​ are normally distributed, then we have Gaussian white noise Xt∼iidN(0,σ2)X_t \\overset{iid}{\\sim}\\mathcal {N} (0, \\sigma^2)Xt​∼iidN(0,σ2). As the mean and acv.f. do not depend on time, the process is second-order stationary. In practice, if all sample ac.f.’s of a series are close to zero, then the series is considered as a realization of a purely random process. Robert H. Shumway, David S. Stoﬀer - Time Series Analysis and its Applications with R Examples ↩︎ The Analysis of Time Series - an Introduction, Chatﬁeld ↩︎ ↩︎ ","link":"https://lyzxh.github.io/post/Time-Series-Basics"},{"title":"Hello Gridea","content":"👏 欢迎使用 Gridea ！ ✍️ Gridea 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ... Github Gridea 主页 示例网站 特性👇 📝 你可以使用最酷的 Markdown 语法，进行快速创作 🌉 你可以给文章配上精美的封面图和在文章任意位置插入图片 🏷️ 你可以对文章进行标签分组 📋 你可以自定义菜单，甚至可以创建外部链接菜单 💻 你可以在 Windows，MacOS 或 Linux 设备上使用此客户端 🌎 你可以使用 𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌 或 Coding Pages 向世界展示，未来将支持更多平台 💬 你可以进行简单的配置，接入 Gitalk 或 DisqusJS 评论系统 🇬🇧 你可以使用中文简体或英语 🌁 你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力 🖥 你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步 🌱 当然 Gridea 还很年轻，有很多不足，但请相信，它会不停向前 🏃 未来，它一定会成为你离不开的伙伴 尽情发挥你的才华吧！ 😘 Enjoy~ ","link":"https://lyzxh.github.io/post/hello-gridea"}]}