{"posts":[{"title":"Time Series Basics","content":"[toc] Definition Stochastic process: A stochastic process is a collection of random variables {Xt}tâˆˆT\\lbrace X_t\\rbrace_{t \\in T}{Xtâ€‹}tâˆˆTâ€‹ indexed by a set TTT , i.e. tâˆˆTt \\in TtâˆˆT defined on a probability space (Î©,F,P)( \\Omega, \\mathcal {F},P)(Î©,F,P). (Not necessarily independent) If TTT consists of the integers (or a subset), the process is called a Discrete Time Stochastic Process. If TTT consists of the real numbers (or a subset), the process is called Continuous Time Stochastic Process. Realization: A realization of {Xt}\\lbrace X_t\\rbrace{Xtâ€‹} is the outcome {xt}tâˆˆT\\lbrace x_t\\rbrace_{t \\in T}{xtâ€‹}tâˆˆTâ€‹ = {Xt(Ï‰)}tâˆˆT\\lbrace X_t(\\omega)\\rbrace_{t \\in T}{Xtâ€‹(Ï‰)}tâˆˆTâ€‹ for some Ï‰âˆˆÎ©\\omega \\in \\OmegaÏ‰âˆˆÎ©. Time Series: 'We use the term time series whether we are referring generically to the process or to a particular realization and make no notational distinction between the two concepts.'[1] Describing a stochastic process A simpler, more useful way of describing a stochastic process is to give the moments of the process, particularly the ï¬rst and second moments that are called the mean and autocovariance function (acv.f.), respectively.[2] Mean The mean function Î¼(t)\\mu(t)Î¼(t) is deï¬ned for all ttt by Î¼(t)=E[X(t)]\\mu(t) = E[X(t)] Î¼(t)=E[X(t)] Autocovariance The variance function Ïƒ2(t)\\sigma^2(t)Ïƒ2(t) is deï¬ned for all ttt by Ïƒ2(t)=Var[X(t)]=E[(X(t)âˆ’Î¼(t))2]\\sigma^2(t)=Var[X(t)]=E[(X(t)-\\mu(t))^2] Ïƒ2(t)=Var[X(t)]=E[(X(t)âˆ’Î¼(t))2] The variance function alone is not enough to specify the second moments of a sequence of random variables. More generally, we deï¬ne the acv.f. Î³(t1,t2)\\gamma(t_1,t_2)Î³(t1â€‹,t2â€‹) to be the covariance of X(t1)X(t_1)X(t1â€‹) with X(t2)X(t_2)X(t2â€‹), namely Î³(t1,t2)=E{[X(t1)âˆ’Î¼(t1)][X(t2)âˆ’Î¼(t2)]}\\gamma(t_1,t_2)=E\\lbrace [X(t_1)-\\mu(t_1)][X(t_2)-\\mu(t_2)]\\rbrace Î³(t1â€‹,t2â€‹)=E{[X(t1â€‹)âˆ’Î¼(t1â€‹)][X(t2â€‹)âˆ’Î¼(t2â€‹)]} The variance function is a special case of the acv.f. when t1=t2t_1 = t_2t1â€‹=t2â€‹. The autocorrelation function is defined as Ï(t1,t2)=Î³(t1,t2){Î³(t1,t1)Î³(t2,t2)}1/2\\rho(t_1,t_2)=\\frac{\\gamma(t_1,t_2)}{\\lbrace \\gamma(t_1,t_1)\\gamma(t_2,t_2)\\rbrace ^{1/2}} Ï(t1â€‹,t2â€‹)={Î³(t1â€‹,t1â€‹)Î³(t2â€‹,t2â€‹)}1/2Î³(t1â€‹,t2â€‹)â€‹ Some classes of stochastic processes Stationary Processes An important class of stochastic processes are those that are stationary. Intuitive Point of View Broadly speaking a time series is said to be stationary if there is no systematic change in mean (no trend), if there is no systematic change in variance and if strictly periodic variations have been removed. In other words, the properties of one section of the data are much like those of any other section.[2:1] Mathematical Deï¬nition A time series is said to be strictly stationary if the joint distribution of X(t1),...,X(tk)X(t_1), . . . , X(t_k)X(t1â€‹),...,X(tkâ€‹) is the same as the joint distribution of X(t1+Ï„),...,X(tk+Ï„)X(t_{1+\\tau}), . . . , X(t_{k+\\tau})X(t1+Ï„â€‹),...,X(tk+Ï„â€‹) for all t1,...,tk,Ï„t_1, . . . , t_k, \\taut1â€‹,...,tkâ€‹,Ï„. second-order stationary (or weakly stationary) if the mean is constant and the covariance function Î³(s,t)\\gamma(s, t)Î³(s,t) depends only on the lag âˆ£tâˆ’sâˆ£(Ï„)|t âˆ’ s|(\\tau)âˆ£tâˆ’sâˆ£(Ï„). Thus, the autocovariance function can be written as Î³(t,t+Ï„)=Î³(0,Ï„)=Î³(0,âˆ’Ï„)â‰¡Î³âˆ£Ï„âˆ£=Î³Ï„\\gamma(t,t+\\tau)=\\gamma(0,\\tau)=\\gamma(0,-\\tau)\\equiv \\gamma_{|\\tau|}=\\gamma_\\tau Î³(t,t+Ï„)=Î³(0,Ï„)=Î³(0,âˆ’Ï„)â‰¡Î³âˆ£Ï„âˆ£â€‹=Î³Ï„â€‹ Ï„âˆˆZ\\tau \\in \\mathcal {Z}Ï„âˆˆZ. The autocorrelation function can be written as Ï(t,t+Ï„)â‰¡Ïâˆ£Ï„âˆ£=ÏÏ„\\rho(t,t+\\tau)\\equiv \\rho_{|\\tau|}=\\rho_\\tau Ï(t,t+Ï„)â‰¡Ïâˆ£Ï„âˆ£â€‹=ÏÏ„â€‹ In the stationary case the covariance and correlation functions are symmetric around Ï„=0\\tau = 0Ï„=0. Purely Random Processes (White Noise) A stochastic process Xt{X_t}Xtâ€‹ is called white noise if its elements are uncorrelated, mean E(Xt)=0E(X_t) = 0E(Xtâ€‹)=0 and variance Var(Xt)=Ïƒ2Var(X_t) = \\sigma^2Var(Xtâ€‹)=Ïƒ2. Î³(k)=Cov(Xt,Xt+k)={ÏƒX2,k=00,k=Â±1,Â±2,...\\gamma(k)=Cov(X_t,X_{t+k})=\\begin{cases}\\sigma^2_X, &amp;k=0 \\cr 0, &amp;k=\\pm1,\\pm2,... \\end{cases} Î³(k)=Cov(Xtâ€‹,Xt+kâ€‹)={ÏƒX2â€‹,0,â€‹k=0k=Â±1,Â±2,...â€‹ Ï(k)=Cor(Xt,Xt+k)={1,k=00,k=Â±1,Â±2,...\\rho(k)=Cor(X_t,X_{t+k})=\\begin{cases}1, &amp;k=0 \\cr 0, &amp;k=\\pm1,\\pm2,... \\end{cases} Ï(k)=Cor(Xtâ€‹,Xt+kâ€‹)={1,0,â€‹k=0k=Â±1,Â±2,...â€‹ If in addition the XtX_tXtâ€‹ are normally distributed, then we have Gaussian white noise Xtâˆ¼iidN(0,Ïƒ2)X_t \\overset{iid}{\\sim}\\mathcal {N} (0, \\sigma^2)Xtâ€‹âˆ¼iidN(0,Ïƒ2). As the mean and acv.f. do not depend on time, the process is second-order stationary. In practice, if all sample ac.f.â€™s of a series are close to zero, then the series is considered as a realization of a purely random process. Robert H. Shumway, David S. Stoï¬€er - Time Series Analysis and its Applications with R Examples â†©ï¸ The Analysis of Time Series - an Introduction, Chatï¬eld â†©ï¸ â†©ï¸ ","link":"https://lyzxh.github.io/post/Time-Series-Basics"},{"title":"Hello Gridea","content":"ğŸ‘ æ¬¢è¿ä½¿ç”¨ Gridea ï¼ âœï¸ Gridea ä¸€ä¸ªé™æ€åšå®¢å†™ä½œå®¢æˆ·ç«¯ã€‚ä½ å¯ä»¥ç”¨å®ƒæ¥è®°å½•ä½ çš„ç”Ÿæ´»ã€å¿ƒæƒ…ã€çŸ¥è¯†ã€ç¬”è®°ã€åˆ›æ„... ... Github Gridea ä¸»é¡µ ç¤ºä¾‹ç½‘ç«™ ç‰¹æ€§ğŸ‘‡ ğŸ“ ä½ å¯ä»¥ä½¿ç”¨æœ€é…·çš„ Markdown è¯­æ³•ï¼Œè¿›è¡Œå¿«é€Ÿåˆ›ä½œ ğŸŒ‰ ä½ å¯ä»¥ç»™æ–‡ç« é…ä¸Šç²¾ç¾çš„å°é¢å›¾å’Œåœ¨æ–‡ç« ä»»æ„ä½ç½®æ’å…¥å›¾ç‰‡ ğŸ·ï¸ ä½ å¯ä»¥å¯¹æ–‡ç« è¿›è¡Œæ ‡ç­¾åˆ†ç»„ ğŸ“‹ ä½ å¯ä»¥è‡ªå®šä¹‰èœå•ï¼Œç”šè‡³å¯ä»¥åˆ›å»ºå¤–éƒ¨é“¾æ¥èœå• ğŸ’» ä½ å¯ä»¥åœ¨ Windowsï¼ŒMacOS æˆ– Linux è®¾å¤‡ä¸Šä½¿ç”¨æ­¤å®¢æˆ·ç«¯ ğŸŒ ä½ å¯ä»¥ä½¿ç”¨ ğ–¦ğ—‚ğ—ğ—ğ—ğ–» ğ–¯ğ–ºğ—€ğ–¾ğ—Œ æˆ– Coding Pages å‘ä¸–ç•Œå±•ç¤ºï¼Œæœªæ¥å°†æ”¯æŒæ›´å¤šå¹³å° ğŸ’¬ ä½ å¯ä»¥è¿›è¡Œç®€å•çš„é…ç½®ï¼Œæ¥å…¥ Gitalk æˆ– DisqusJS è¯„è®ºç³»ç»Ÿ ğŸ‡¬ğŸ‡§ ä½ å¯ä»¥ä½¿ç”¨ä¸­æ–‡ç®€ä½“æˆ–è‹±è¯­ ğŸŒ ä½ å¯ä»¥ä»»æ„ä½¿ç”¨åº”ç”¨å†…é»˜è®¤ä¸»é¢˜æˆ–ä»»æ„ç¬¬ä¸‰æ–¹ä¸»é¢˜ï¼Œå¼ºå¤§çš„ä¸»é¢˜è‡ªå®šä¹‰èƒ½åŠ› ğŸ–¥ ä½ å¯ä»¥è‡ªå®šä¹‰æºæ–‡ä»¶å¤¹ï¼Œåˆ©ç”¨ OneDriveã€ç™¾åº¦ç½‘ç›˜ã€iCloudã€Dropbox ç­‰è¿›è¡Œå¤šè®¾å¤‡åŒæ­¥ ğŸŒ± å½“ç„¶ Gridea è¿˜å¾ˆå¹´è½»ï¼Œæœ‰å¾ˆå¤šä¸è¶³ï¼Œä½†è¯·ç›¸ä¿¡ï¼Œå®ƒä¼šä¸åœå‘å‰ ğŸƒ æœªæ¥ï¼Œå®ƒä¸€å®šä¼šæˆä¸ºä½ ç¦»ä¸å¼€çš„ä¼™ä¼´ å°½æƒ…å‘æŒ¥ä½ çš„æ‰åå§ï¼ ğŸ˜˜ Enjoy~ ","link":"https://lyzxh.github.io/post/hello-gridea"}]}